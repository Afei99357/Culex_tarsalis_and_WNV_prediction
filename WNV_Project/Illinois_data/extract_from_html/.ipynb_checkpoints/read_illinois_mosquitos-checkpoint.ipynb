{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "from lxml import html\n",
    "import lmdbm\n",
    "import lzma\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "http_cache = lmdbm.open(\"wnv_http_cache.lmdb\", flag=\"c\")\n",
    "def cache_get(url):\n",
    "    if url not in http_cache:\n",
    "        http_cache[url] = lzma.compress(pickle.dumps(requests.get(url).text))\n",
    "        time.sleep(1)\n",
    "        http_cache.sync()\n",
    "    return pickle.loads(lzma.decompress(http_cache[url]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_counties_for_year(year):\n",
    "    text = cache_get(f\"http://www.idph.state.il.us/envhealth/wnvsurveillance_data_{year:02}.htm\")\n",
    "    root = html.fromstring(text)\n",
    "    return set([e.text.strip() for e in root.xpath(\"//td[@width='475']//table//td[position()=1]/font/a\")])\n",
    "\n",
    "def get_all_counties():\n",
    "    counties = set()\n",
    "    for year in range(2, 16):\n",
    "        counties |= get_counties_for_year(year)\n",
    "    return counties\n",
    "\n",
    "all_counties = get_all_counties()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_tables(logs):\n",
    "    human_tables = []\n",
    "    animal_tables = []\n",
    "\n",
    "    for county in all_counties:\n",
    "        for year in range(2, 16):\n",
    "            def emit(m):\n",
    "                print(f\"{county} {year}: {m}\")\n",
    "                logs.append((county, year, m))\n",
    "            emit(\"start\")\n",
    "            try:\n",
    "                clean_county_name = county.lower().replace(\".\", \"\").replace(\" \", \"\")\n",
    "                table_page_text = cache_get(f\"http://www.idph.state.il.us/envhealth/wnvcounty/wnv{clean_county_name}{year:02}.htm\")\n",
    "            except Exception as e:\n",
    "                emit((\"Failed to download \", e))\n",
    "                continue\n",
    "            try:\n",
    "                table_page_root = html.fromstring(table_page_text)\n",
    "            except Exception as e:\n",
    "                emit((\"Failed to parse \", e))\n",
    "                continue\n",
    "            try:\n",
    "                tables_in_detail_page = [\n",
    "                    t\n",
    "                    for t in table_page_root.xpath(\"//table\")\n",
    "                    if \"municipality\" in html.tostring(t.xpath(\"//tr[position()=1]\")).lower()\n",
    "                ]\n",
    "                \n",
    "            except Exception as e:\n",
    "                emit((\"Failed to extract \", e))\n",
    "                continue\n",
    "            \n",
    "            if len(tables_in_detail_page) == 1:\n",
    "                # only animals\n",
    "                animal_table = tables_in_detail_page[0]\n",
    "                animal_table = html.tostring(animal_table)\n",
    "                animal_table = pd.read_html(animal_table, header=0)[0]\n",
    "                animal_tables.append(animal_table)\n",
    "                emit(\"has animals\")\n",
    "            elif len(tables_in_detail_page) == 2:\n",
    "                # humans and animals\n",
    "                human_table = tables_in_detail_page[0]\n",
    "                human_table = html.tostring(human_table)\n",
    "                human_table = pd.read_html(human_table, header=0)[0]\n",
    "                human_tables.append(human_table)\n",
    "                emit(\"has humans\")\n",
    "\n",
    "                animal_table = tables_in_detail_page[1]\n",
    "                animal_table = html.tostring(animal_table)\n",
    "                animal_table = pd.read_html(animal_table, header=0)[0]\n",
    "                animal_tables.append(animal_table)\n",
    "                emit(\"has animals\")\n",
    "            else:\n",
    "                emit(\"has no tables\")\n",
    "            \n",
    "            emit(\"success\")\n",
    "    \n",
    "    return pd.concat(human_tables) if human_tables else None, pd.concat(animal_tables) if animal_tables else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jefferson 2: start\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'e' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 23\u001b[0m, in \u001b[0;36mget_tables\u001b[0;34m(logs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 23\u001b[0m     tables_in_detail_page \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     24\u001b[0m         t\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m table_page_root\u001b[38;5;241m.\u001b[39mxpath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//table\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmunicipality\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m html\u001b[38;5;241m.\u001b[39mtostring(t\u001b[38;5;241m.\u001b[39mxpath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//tr[position()=1]\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m     27\u001b[0m     ]\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[4], line 26\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     tables_in_detail_page \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     24\u001b[0m         t\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m table_page_root\u001b[38;5;241m.\u001b[39mxpath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//table\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmunicipality\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mhtml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtostring\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxpath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m//tr[position()=1]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m     27\u001b[0m     ]\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/lxml/html/__init__.py:1864\u001b[0m, in \u001b[0;36mtostring\u001b[0;34m(doc, pretty_print, include_meta_content_type, encoding, method, with_tail, doctype)\u001b[0m\n\u001b[1;32m   1803\u001b[0m \u001b[38;5;124;03m\"\"\"Return an HTML string representation of the document.\u001b[39;00m\n\u001b[1;32m   1804\u001b[0m \n\u001b[1;32m   1805\u001b[0m \u001b[38;5;124;03mNote: if include_meta_content_type is true this will create a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1862\u001b[0m \u001b[38;5;124;03m    <html><body><p>Hello<br>world!</p></body></html>\u001b[39;00m\n\u001b[1;32m   1863\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1864\u001b[0m html \u001b[38;5;241m=\u001b[39m \u001b[43metree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtostring\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretty_print\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretty_print\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_tail\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_tail\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1866\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mdoctype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoctype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m include_meta_content_type:\n",
      "File \u001b[0;32msrc/lxml/etree.pyx:3465\u001b[0m, in \u001b[0;36mlxml.etree.tostring\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Type 'list' cannot be serialized.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m logs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m human_tables, animal_tables \u001b[38;5;241m=\u001b[39m \u001b[43mget_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 29\u001b[0m, in \u001b[0;36mget_tables\u001b[0;34m(logs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     tables_in_detail_page \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     24\u001b[0m         t\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m table_page_root\u001b[38;5;241m.\u001b[39mxpath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//table\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmunicipality\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m html\u001b[38;5;241m.\u001b[39mtostring(t\u001b[38;5;241m.\u001b[39mxpath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//tr[position()=1]\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m     27\u001b[0m     ]\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[43me\u001b[49m:\n\u001b[1;32m     30\u001b[0m     emit((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to extract \u001b[39m\u001b[38;5;124m\"\u001b[39m, e))\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'e' is not defined"
     ]
    }
   ],
   "source": [
    "logs = []\n",
    "human_tables, animal_tables = get_tables(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "http_cache.sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Adams',\n",
       " 'Bond',\n",
       " ' Bureau',\n",
       " ' Champaign',\n",
       " ' Clinton',\n",
       " ' Cook',\n",
       " ' DuPage',\n",
       " ' Edgar',\n",
       " ' Franklin',\n",
       " ' Gallatin',\n",
       " ' Grundy',\n",
       " ' Jackson',\n",
       " ' Jersey',\n",
       " ' Kane',\n",
       " ' Kendall',\n",
       " ' Knox',\n",
       " ' Lake',\n",
       " ' LaSalle',\n",
       " ' Macon',\n",
       " ' Macoupin',\n",
       " ' Madison',\n",
       " ' Marion',\n",
       " ' Massac',\n",
       " ' Mercer',\n",
       " ' Ogle',\n",
       " ' Perry',\n",
       " ' St. Clair',\n",
       " ' Sangamon',\n",
       " ' Stephenson',\n",
       " ' Tazewell',\n",
       " ' Warren',\n",
       " ' Washington',\n",
       " ' Wayne',\n",
       " ' Will',\n",
       " ' Williamson',\n",
       " ' Winnebago']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = requests.get(\"http://www.idph.state.il.us/envhealth/wnvsurveillance_data_09.htm\").text\n",
    "root = html.fromstring(text)\n",
    "[e.text for e in root.xpath(\"//td[@width='475']//table//td[position()=1]/font/a\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_tables.to_csv(\"/Users/ericliao/Desktop/human_tables.csv\")\n",
    "animal_tables.to_csv(\"/Users/ericliao/Desktop/animal_tables.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
